#!/usr/bin/env python3
"""
Integrated P900 Network Performance Tester
ØªØ³ØªØ± ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªØ£Ø«ÛŒØ± ØªØ±Ø§ÙÛŒÚ© MAVLink Ø¨Ø± RTT Ø´Ø¨Ú©Ù‡ P900

Ø§ÛŒÙ† ØªØ³ØªØ± ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø²:
- TrafficSimulator: Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ±Ø§ÙÛŒÚ© MAVLink ÙˆØ§Ù‚Ø¹ÛŒ
- ProbeInjector: Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ RTT
- ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† ØªØ±Ø§ÙÛŒÚ© Ùˆ ØªØ£Ø®ÛŒØ±
"""

import time
import json
import threading
import queue
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict, field
from datetime import datetime
from enum import Enum
import logging
import numpy as np
import serial
import sys

# Import existing components
from traffic_simulator import TrafficSimulator
from probe_injector import ProbeInjector
from mavlink_profile import MAVLinkProfile
from packet_generator import PacketGenerator

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Data Structures and Enums
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestScenario(Enum):
    """Ø§Ù†ÙˆØ§Ø¹ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ØªØ³Øª"""
    BASELINE = "baseline"           # ÙÙ‚Ø· probeØŒ Ø¨Ø¯ÙˆÙ† ØªØ±Ø§ÙÛŒÚ©
    LIGHT_TRAFFIC = "light"        # 10% bandwidth utilization
    MEDIUM_TRAFFIC = "medium"      # 50% bandwidth utilization
    HEAVY_TRAFFIC = "heavy"        # 90% bandwidth utilization
    BURST_TRAFFIC = "burst"        # ØªØ±Ø§ÙÛŒÚ© Ù…ØªØºÛŒØ±
    CUSTOM = "custom"              # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÙØ§Ø±Ø´ÛŒ

@dataclass
class ScenarioConfig:
    """Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ÛŒÚ© Ø³Ù†Ø§Ø±ÛŒÙˆ ØªØ³Øª"""
    name: str
    description: str
    traffic_enabled: bool
    target_bandwidth_bps: float
    probe_interval_ms: float
    probe_count: int
    test_duration_seconds: float
    warmup_seconds: float = 2.0
    cooldown_seconds: float = 1.0

@dataclass
class TestMetadata:
    """Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ ÛŒÚ© ØªØ³Øª"""
    test_id: str
    timestamp: str
    scenario: str
    serial_ports: Dict[str, str]
    baudrate: int
    total_duration: float = 0.0

@dataclass
class CombinedResults:
    """Ù†ØªØ§ÛŒØ¬ ØªØ±Ú©ÛŒØ¨ÛŒ ØªØ³Øª"""
    metadata: TestMetadata
    baseline_metrics: Optional[Dict] = None
    traffic_metrics: Optional[Dict] = None
    under_traffic_metrics: Optional[Dict] = None
    correlation_analysis: Optional[Dict] = None
    raw_measurements: List[Dict] = field(default_factory=list)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Scenario Manager - Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ØªØ³Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ScenarioManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ØªØ³Øª"""

    # ØªØ¹Ø±ÛŒÙ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    PREDEFINED_SCENARIOS = {
        TestScenario.BASELINE: ScenarioConfig(
            name="Baseline",
            description="RTT measurement without traffic",
            traffic_enabled=False,
            target_bandwidth_bps=0,
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        ),
        TestScenario.LIGHT_TRAFFIC: ScenarioConfig(
            name="Light Traffic",
            description="10% bandwidth utilization",
            traffic_enabled=True,
            target_bandwidth_bps=5760,  # 10% of 57600
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        ),
        TestScenario.MEDIUM_TRAFFIC: ScenarioConfig(
            name="Medium Traffic",
            description="50% bandwidth utilization",
            traffic_enabled=True,
            target_bandwidth_bps=28800,  # 50% of 57600
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        ),
        TestScenario.HEAVY_TRAFFIC: ScenarioConfig(
            name="Heavy Traffic",
            description="90% bandwidth utilization",
            traffic_enabled=True,
            target_bandwidth_bps=51840,  # 90% of 57600
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        )
    }

    @classmethod
    def get_scenario(cls, scenario_type: TestScenario) -> ScenarioConfig:
        """Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆ"""
        return cls.PREDEFINED_SCENARIOS.get(
            scenario_type,
            cls.PREDEFINED_SCENARIOS[TestScenario.BASELINE]
        )

    @classmethod
    def create_custom_scenario(cls, **kwargs) -> ScenarioConfig:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø³ÙØ§Ø±Ø´ÛŒ"""
        defaults = asdict(cls.PREDEFINED_SCENARIOS[TestScenario.BASELINE])
        defaults.update(kwargs)
        defaults['name'] = kwargs.get('name', 'Custom')
        defaults['description'] = kwargs.get('description', 'Custom scenario')
        return ScenarioConfig(**defaults)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Component Integrator - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ComponentIntegrator:
    """ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"""

    def __init__(self, master_port: str, slave_port: str, baudrate: int = 57600):
        """
        Args:
            master_port: Ù¾ÙˆØ±Øª Ù…Ø­Ù„ÛŒ (Master) - Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª Ø³Ø±ÛŒØ§Ù„
            slave_port: Ù¾ÙˆØ±Øª Ø¯ÙˆØ± (Slave) - Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª Ø³Ø±ÛŒØ§Ù„
            baudrate: Ø³Ø±Ø¹Øª Ø³Ø±ÛŒØ§Ù„
        """
        self.master_port = master_port  # Ø±Ø´ØªÙ‡ Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª
        self.slave_port = slave_port    # Ø±Ø´ØªÙ‡ Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª
        self.baudrate = baudrate

        # Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
        self.traffic_simulator: Optional[TrafficSimulator] = None
        self.probe_injector: Optional[ProbeInjector] = None
        self.mavlink_profile: Optional[MAVLinkProfile] = None

        # Serial connections - Ø§ÛŒÙ†Ù‡Ø§ Ø´ÛŒØ¡ Serial Ù‡Ø³ØªÙ†Ø¯
        self.master_serial: Optional[serial.Serial] = None
        self.slave_serial: Optional[serial.Serial] = None

        # Component status
        self.components_ready = False
        self.serial_lock = threading.Lock()

    def initialize_serial_ports(self) -> bool:
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ§Ù„"""
        try:
            # Master port - Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù†
            logger.info(f"Opening master port: {self.master_port}")
            self.master_serial = serial.Serial(
                port=self.master_port,  # Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª
                baudrate=self.baudrate,
                timeout=0.1,
                write_timeout=1.0
            )
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾ÙˆØ±Øª
            if not self.master_serial.is_open:
                logger.warning("Master port created but not open, attempting to open...")
                self.master_serial.open()
            
            if self.master_serial.is_open:
                logger.info(f"âœ… Master serial port opened successfully: {self.master_serial}")
            else:
                raise RuntimeError(f"Failed to open master port: {self.master_port}")

            # Slave port - Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù†
            logger.info(f"Opening slave port: {self.slave_port}")
            self.slave_serial = serial.Serial(
                port=self.slave_port,  # Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª
                baudrate=self.baudrate,
                timeout=0.1,
                write_timeout=1.0
            )
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾ÙˆØ±Øª
            if not self.slave_serial.is_open:
                logger.warning("Slave port created but not open, attempting to open...")
                self.slave_serial.open()
                
            if self.slave_serial.is_open:
                logger.info(f"âœ… Slave serial port opened successfully: {self.slave_serial}")
            else:
                raise RuntimeError(f"Failed to open slave port: {self.slave_port}")

            # Clear buffers - ÙÙ‚Ø· Ø§Ú¯Ø± Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ Ø¨Ø§Ø² Ø¨Ø§Ø´Ù†Ø¯
            if self.master_serial.is_open:
                self.master_serial.reset_input_buffer()
                self.master_serial.reset_output_buffer()
                logger.debug("Master port buffers cleared")
            
            if self.slave_serial.is_open:
                self.slave_serial.reset_input_buffer()
                self.slave_serial.reset_output_buffer()
                logger.debug("Slave port buffers cleared")

            logger.info("âœ… Both serial ports initialized successfully")
            return True

        except serial.SerialException as e:
            logger.error(f"âŒ Serial port error: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ Failed to initialize serial ports: {e}")
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø³ØªÙ† Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ù†ÛŒÙ…Ù‡â€ŒØ¨Ø§Ø²
            if self.master_serial and self.master_serial.is_open:
                self.master_serial.close()
            if self.slave_serial and self.slave_serial.is_open:
                self.slave_serial.close()
            return False

    def create_traffic_simulator(self, target_bandwidth: float) -> TrafficSimulator:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø² ØªØ±Ø§ÙÛŒÚ©"""
        if not self.master_serial or not self.master_serial.is_open:
            raise RuntimeError("Master serial port not initialized or not open")

        # TrafficSimulator Ø§Ù†ØªØ¸Ø§Ø± serial object Ø¯Ø§Ø±Ø¯ØŒ Ù†Ù‡ string
        self.traffic_simulator = TrafficSimulator(
            serial_port=self.master_serial,  # Ø´ÛŒØ¡ Serial
            target_bandwidth=target_bandwidth,
            write_lock=self.serial_lock
        )
        logger.info(f"âœ… Traffic simulator created (target: {target_bandwidth} bps)")
        return self.traffic_simulator

    def create_probe_injector(self) -> ProbeInjector:
        """Ø§ÛŒØ¬Ø§Ø¯ ØªØ²Ø±ÛŒÙ‚â€ŒÚ©Ù†Ù†Ø¯Ù‡ probe"""
        if not self.master_serial or not self.slave_serial:
            raise RuntimeError("Serial ports not initialized")
        
        if not self.master_serial.is_open or not self.slave_serial.is_open:
            raise RuntimeError("Serial ports not open")

        # ProbeInjector Ø§Ù†ØªØ¸Ø§Ø± serial objects Ø¯Ø§Ø±Ø¯
        # ØªÙˆØ¬Ù‡: Ù†Ø§Ù… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¯Ø± ProbeInjector Ø¨Ø§ÛŒØ¯ Ø¨Ø±Ø±Ø³ÛŒ Ø´ÙˆØ¯
        self.probe_injector = ProbeInjector(
            master_serial=self.master_serial,  # Ø´ÛŒØ¡ Serial (Ù†Ù‡ string)
            slave_serial=self.slave_serial      # Ø´ÛŒØ¡ Serial (Ù†Ù‡ string)
        )
        logger.info("âœ… Probe injector created")
        return self.probe_injector

    def load_mavlink_profile(self, profile_path: Optional[str] = None) -> MAVLinkProfile:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ MAVLink"""
        self.mavlink_profile = MAVLinkProfile(profile_path)
        logger.info("âœ… MAVLink profile loaded")
        return self.mavlink_profile

    def cleanup(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
        try:
            if self.master_serial and self.master_serial.is_open:
                self.master_serial.close()
                logger.info("Master serial port closed")

            if self.slave_serial and self.slave_serial.is_open:
                self.slave_serial.close()
                logger.info("Slave serial port closed")
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test Orchestrator - Ù‡Ù…Ø§Ù‡Ù†Ú¯â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§ØµÙ„ÛŒ ØªØ³Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class IntegratedP900Tester:
    """ØªØ³ØªØ± ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ P900 - ØªØ±Ú©ÛŒØ¨ ØªØ±Ø§ÙÛŒÚ© Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ RTT"""

    def __init__(self, master_port: str, slave_port: str, baudrate: int = 57600):
        """
        Args:
            master_port: Ù¾ÙˆØ±Øª Master (Ù…Ø­Ù„ÛŒ) - Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª
            slave_port: Ù¾ÙˆØ±Øª Slave (Ø¯ÙˆØ±) - Ù…Ø³ÛŒØ± Ù¾ÙˆØ±Øª
            baudrate: Ø³Ø±Ø¹Øª Ø³Ø±ÛŒØ§Ù„
        """
        # Configuration
        self.master_port = master_port
        self.slave_port = slave_port
        self.baudrate = baudrate

        # Components
        self.integrator = ComponentIntegrator(master_port, slave_port, baudrate)
        self.scenario_manager = ScenarioManager()

        # Results storage
        self.test_results: List[CombinedResults] = []
        self.current_test: Optional[CombinedResults] = None

        # Thread management
        self.traffic_thread: Optional[threading.Thread] = None
        self.probe_thread: Optional[threading.Thread] = None
        self.monitor_thread: Optional[threading.Thread] = None

        # Synchronization
        self.test_running = False
        self.traffic_active = threading.Event()
        self.results_queue = queue.Queue()

        # Statistics
        self.traffic_stats = {}
        self.probe_stats = {}

    def initialize(self) -> bool:
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø³ÛŒØ³ØªÙ…"""
        logger.info("="*60)
        logger.info("ğŸš€ Initializing Integrated P900 Tester")
        logger.info("="*60)

        # Initialize serial ports
        if not self.integrator.initialize_serial_ports():
            logger.error("Failed to initialize serial ports")
            return False

        # Load MAVLink profile
        try:
            self.integrator.load_mavlink_profile()
        except Exception as e:
            logger.error(f"Failed to load MAVLink profile: {e}")
            # Ø§ÛŒÙ† Ø®Ø·Ø§ critical Ù†ÛŒØ³ØªØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒÙ…
            
        logger.info("âœ… System initialized successfully")
        return True

    def run_scenario(self, scenario: TestScenario) -> CombinedResults:
        """Ø§Ø¬Ø±Ø§ÛŒ ÛŒÚ© Ø³Ù†Ø§Ø±ÛŒÙˆ ØªØ³Øª Ú©Ø§Ù…Ù„"""
        config = self.scenario_manager.get_scenario(scenario)
        logger.info(f"\nğŸ“‹ Running scenario: {config.name}")
        logger.info(f"   Description: {config.description}")

        # Create test metadata
        test_id = f"p900_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        metadata = TestMetadata(
            test_id=test_id,
            timestamp=datetime.now().isoformat(),
            scenario=config.name,
            serial_ports={
                'master': self.master_port,
                'slave': self.slave_port
            },
            baudrate=self.baudrate
        )

        # Initialize results container
        self.current_test = CombinedResults(metadata=metadata)

        # Execute test phases
        start_time = time.perf_counter()

        try:
            # Phase 1: Baseline measurement (always)
            logger.info("\nğŸ“Š Phase 1: Baseline Measurement")
            baseline_metrics = self._run_baseline_measurement(config)
            self.current_test.baseline_metrics = baseline_metrics

            # Phase 2: Traffic + Probe (if traffic enabled)
            if config.traffic_enabled:
                logger.info("\nğŸ“Š Phase 2: Combined Traffic + Probe Measurement")
                combined_metrics = self._run_combined_measurement(config)
                self.current_test.under_traffic_metrics = combined_metrics['probe_metrics']
                self.current_test.traffic_metrics = combined_metrics['traffic_metrics']

                # Phase 3: Correlation analysis
                logger.info("\nğŸ“Š Phase 3: Correlation Analysis")
                correlation = self._analyze_correlation()
                self.current_test.correlation_analysis = correlation

            # Update metadata
            self.current_test.metadata.total_duration = time.perf_counter() - start_time

            # Store results
            self.test_results.append(self.current_test)

            logger.info(f"\nâœ… Scenario '{config.name}' completed successfully!")
            return self.current_test

        except Exception as e:
            logger.error(f"âŒ Error during scenario execution: {e}")
            raise

    def _run_baseline_measurement(self, config: ScenarioConfig) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ baseline (Ø¨Ø¯ÙˆÙ† ØªØ±Ø§ÙÛŒÚ©)"""
        logger.info("  â±ï¸ Starting baseline measurement...")

        try:
            # Create probe injector Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª baseline
            probe = self.integrator.create_probe_injector()

            # ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
            probe.interval_ms = config.probe_interval_ms
            probe.timeout_ms = 500  # 500ms timeout

            # Ø´Ø±ÙˆØ¹ probe injection
            probe.start()

            # Ø§Ø¬Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Øª Ù…Ø´Ø®Øµ
            test_duration = min(config.test_duration_seconds, 30)  # Ø­Ø¯Ø§Ú©Ø«Ø± 30 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ baseline
            logger.info(f"  Running baseline for {test_duration} seconds...")

            start_time = time.perf_counter()
            while time.perf_counter() - start_time < test_duration:
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ù‡Ø± 5 Ø«Ø§Ù†ÛŒÙ‡
                if int(time.perf_counter() - start_time) % 5 == 0:
                    stats = probe.get_statistics()
                    logger.info(f"    Progress: Sent={stats.total_sent}, "
                              f"Received={stats.total_received}, "
                              f"Loss={stats.loss_rate:.1f}%")
                time.sleep(1)

            # ØªÙˆÙ‚Ù Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬
            probe.stop()
            final_stats = probe.get_statistics()

            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
            baseline_metrics = {
                'probe_count': final_stats.total_sent,
                'successful_probes': final_stats.total_received,
                'loss_rate': final_stats.loss_rate,
                'rtt': {
                    'mean': final_stats.avg_rtt_ms,
                    'min': final_stats.min_rtt_ms,
                    'max': final_stats.max_rtt_ms,
                    'std': final_stats.std_rtt_ms,
                    'p95': final_stats.percentile_95_ms,
                    'p99': final_stats.percentile_99_ms
                },
                'jitter': {
                    'mean': final_stats.avg_jitter_ms,
                    'max': final_stats.max_jitter_ms
                },
                'test_duration': test_duration
            }

            logger.info(f"  âœ… Baseline complete: RTT={final_stats.avg_rtt_ms:.2f}ms, "
                       f"Loss={final_stats.loss_rate:.1f}%")

            return baseline_metrics

        except Exception as e:
            logger.error(f"âŒ Error in baseline measurement: {e}")
            raise

    def _run_combined_measurement(self, config: ScenarioConfig) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ (ØªØ±Ø§ÙÛŒÚ© + Ù¾Ø±ÙˆØ¨)"""
        logger.info("  ğŸ”„ Starting combined measurement...")

        try:
            # Phase 2.1: Start traffic generation
            traffic_sim = self.integrator.create_traffic_simulator(
                target_bandwidth=config.target_bandwidth_bps
            )

            # Ø´Ø±ÙˆØ¹ ØªØ±Ø§ÙÛŒÚ© Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            self.traffic_active.clear()
            traffic_thread = threading.Thread(
                target=self._run_traffic_generator,
                args=(traffic_sim, config.test_duration_seconds),
                name="TrafficGenerator"
            )
            traffic_thread.start()

            # ØµØ¨Ø± Ø¨Ø±Ø§ÛŒ warmup ØªØ±Ø§ÙÛŒÚ©
            logger.info(f"  â³ Warming up traffic for {config.warmup_seconds}s...")
            time.sleep(config.warmup_seconds)

            # Phase 2.2: Start probe injection with traffic
            probe = self.integrator.create_probe_injector()
            probe.interval_ms = config.probe_interval_ms
            probe.timeout_ms = 500

            probe.start()

            # Monitor both traffic and probes
            monitor_start = time.perf_counter()
            probe_duration = config.test_duration_seconds - config.warmup_seconds

            logger.info(f"  ğŸ“Š Measuring RTT under traffic load for {probe_duration}s...")

            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¢Ù…Ø§Ø± Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ
            periodic_stats = []

            while time.perf_counter() - monitor_start < probe_duration:
                # Ø«Ø¨Øª Ø¢Ù…Ø§Ø± Ù‡Ø± Ø«Ø§Ù†ÛŒÙ‡
                current_time = time.perf_counter() - monitor_start

                # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
                probe_stats = probe.get_statistics()
                traffic_stats = traffic_sim.get_stats()

                periodic_stats.append({
                    'timestamp': current_time,
                    'probe_stats': {
                        'sent': probe_stats.total_sent,
                        'received': probe_stats.total_received,
                        'rtt_ms': probe_stats.avg_rtt_ms,
                        'loss_rate': probe_stats.loss_rate
                    },
                    'traffic_stats': {
                        'packets_sent': traffic_stats.get('packets_sent', 0),
                        'bytes_sent': traffic_stats.get('bytes_sent', 0),
                        'actual_bandwidth': traffic_stats.get('actual_bandwidth', 0)
                    }
                })

                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ù‡Ø± 5 Ø«Ø§Ù†ÛŒÙ‡
                if int(current_time) % 5 == 0 and int(current_time) > 0:
                    logger.info(f"    Progress: Time={int(current_time)}s, "
                              f"RTT={probe_stats.avg_rtt_ms:.2f}ms, "
                              f"Traffic={traffic_stats.get('actual_bandwidth', 0):.0f}bps")

                time.sleep(1)

            # ØªÙˆÙ‚Ù Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
            logger.info("  ğŸ›‘ Stopping components...")
            probe.stop()
            self.traffic_active.set()  # Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªÙˆÙ‚Ù Ø¨Ù‡ traffic
            traffic_thread.join(timeout=2)

            # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
            final_probe_stats = probe.get_statistics()
            final_traffic_stats = traffic_sim.get_stats()

            # Ø³Ø§Ø®ØªØ§Ø± Ù†ØªØ§ÛŒØ¬ ØªØ±Ú©ÛŒØ¨ÛŒ
            combined_metrics = {
                'probe_metrics': {
                    'probe_count': final_probe_stats.total_sent,
                    'successful_probes': final_probe_stats.total_received,
                    'loss_rate': final_probe_stats.loss_rate,
                    'rtt': {
                        'mean': final_probe_stats.avg_rtt_ms,
                        'min': final_probe_stats.min_rtt_ms,
                        'max': final_probe_stats.max_rtt_ms,
                        'std': final_probe_stats.std_rtt_ms,
                        'p95': final_probe_stats.percentile_95_ms,
                        'p99': final_probe_stats.percentile_99_ms
                    },
                    'jitter': {
                        'mean': final_probe_stats.avg_jitter_ms,
                        'max': final_probe_stats.max_jitter_ms
                    }
                },
                'traffic_metrics': {
                    'target_bandwidth': config.target_bandwidth_bps,
                    'actual_bandwidth': final_traffic_stats.get('actual_bandwidth', 0),
                    'total_packets': final_traffic_stats.get('packets_sent', 0),
                    'total_bytes': final_traffic_stats.get('bytes_sent', 0),
                    'duration': final_traffic_stats.get('elapsed_time', 0),
                    'errors': final_traffic_stats.get('errors', 0)
                },
                'periodic_measurements': periodic_stats
            }

            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± raw measurements Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø¹Ø¯ÛŒ
            self.current_test.raw_measurements = periodic_stats

            logger.info(f"  âœ… Combined measurement complete: "
                       f"RTT={final_probe_stats.avg_rtt_ms:.2f}ms under "
                       f"{final_traffic_stats.get('actual_bandwidth', 0):.0f}bps traffic")

            return combined_metrics

        except Exception as e:
            logger.error(f"âŒ Error in combined measurement: {e}")
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚Ù Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
            self.traffic_active.set()
            raise

    def _run_traffic_generator(self, traffic_sim: TrafficSimulator, duration: float):
        """Ø§Ø¬Ø±Ø§ÛŒ traffic generator Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡"""
        try:
            logger.debug(f"Traffic generator thread started for {duration}s")
            start_time = time.perf_counter()
            
            # Ø´Ø±ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ ØªØ±Ø§ÙÛŒÚ©
            traffic_sim.running = True
            
            while time.perf_counter() - start_time < duration:
                if self.traffic_active.is_set():
                    logger.debug("Traffic generation stopped by signal")
                    break
                    
                # Ø§Ø±Ø³Ø§Ù„ Ù¾Ú©Øª
                traffic_sim._send_single_packet()
                
                # Ú©Ù†ØªØ±Ù„ Ù†Ø±Ø® Ø§Ø±Ø³Ø§Ù„
                time.sleep(traffic_sim.packet_interval)
            
            traffic_sim.running = False
            logger.debug("Traffic generator thread completed")
            
        except Exception as e:
            logger.error(f"Error in traffic generator thread: {e}")

    def _analyze_correlation(self) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† ØªØ±Ø§ÙÛŒÚ© Ùˆ ØªØ£Ø®ÛŒØ±"""
        if not self.current_test or not self.current_test.raw_measurements:
            return {}

        try:
            measurements = self.current_test.raw_measurements
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ
            timestamps = [m['timestamp'] for m in measurements]
            rtt_values = [m['probe_stats']['rtt_ms'] for m in measurements]
            bandwidth_values = [m['traffic_stats']['actual_bandwidth'] for m in measurements]
            
# Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø¯ Ø§Ø² Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ù‚Ø·Ø¹ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯...

            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
            if len(rtt_values) > 1 and len(bandwidth_values) > 1:
                correlation_coefficient = np.corrcoef(rtt_values, bandwidth_values)[0, 1]
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ Ø³Ø§Ø¯Ù‡
                z = np.polyfit(bandwidth_values, rtt_values, 1)
                p = np.poly1d(z)
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ R-squared
                y_pred = p(bandwidth_values)
                ss_res = np.sum((rtt_values - y_pred) ** 2)
                ss_tot = np.sum((rtt_values - np.mean(rtt_values)) ** 2)
                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                
                correlation_analysis = {
                    'correlation_coefficient': float(correlation_coefficient),
                    'r_squared': float(r_squared),
                    'regression_slope': float(z[0]),
                    'regression_intercept': float(z[1]),
                    'impact_assessment': {
                        'low': 'Minimal impact' if abs(correlation_coefficient) < 0.3 else 'Some impact',
                        'medium': 'Moderate impact' if 0.3 <= abs(correlation_coefficient) < 0.7 else 'Significant impact',
                        'high': 'Strong impact' if abs(correlation_coefficient) >= 0.7 else 'Variable impact'
                    }
                }
                
                # ØªØ­Ù„ÛŒÙ„ ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø³Ø¨ÛŒ
                if self.current_test.baseline_metrics and self.current_test.under_traffic_metrics:
                    baseline_rtt = self.current_test.baseline_metrics['rtt']['mean']
                    traffic_rtt = self.current_test.under_traffic_metrics['rtt']['mean']
                    
                    baseline_loss = self.current_test.baseline_metrics['loss_rate']
                    traffic_loss = self.current_test.under_traffic_metrics['loss_rate']
                    
                    correlation_analysis['relative_changes'] = {
                        'rtt_increase_percent': ((traffic_rtt - baseline_rtt) / baseline_rtt * 100) if baseline_rtt > 0 else 0,
                        'rtt_increase_ms': traffic_rtt - baseline_rtt,
                        'loss_increase_percent': traffic_loss - baseline_loss,
                        'baseline_rtt_ms': baseline_rtt,
                        'traffic_rtt_ms': traffic_rtt
                    }
                    
                logger.info(f"  ğŸ“Š Correlation coefficient: {correlation_coefficient:.3f}")
                logger.info(f"  ğŸ“ˆ RTT increase under traffic: {correlation_analysis.get('relative_changes', {}).get('rtt_increase_percent', 0):.1f}%")
                
                return correlation_analysis
            else:
                logger.warning("Insufficient data for correlation analysis")
                return {}
                
        except Exception as e:
            logger.error(f"Error in correlation analysis: {e}")
            return {}

    def run_all_scenarios(self) -> List[CombinedResults]:
        """Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ Running All Standard Scenarios")
        logger.info("="*60)
        
        scenarios = [
            TestScenario.BASELINE,
            TestScenario.LIGHT_TRAFFIC,
            TestScenario.MEDIUM_TRAFFIC,
            TestScenario.HEAVY_TRAFFIC
        ]
        
        results = []
        for scenario in scenarios:
            try:
                logger.info(f"\n{'='*40}")
                logger.info(f"Scenario {scenarios.index(scenario) + 1}/{len(scenarios)}")
                result = self.run_scenario(scenario)
                results.append(result)
                
                # Ú©Ù…ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª Ø¨ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§
                if scenario != scenarios[-1]:
                    logger.info("â³ Cooling down for 5 seconds...")
                    time.sleep(5)
                    
            except Exception as e:
                logger.error(f"Failed to run scenario {scenario.value}: {e}")
                continue
        
        return results

    def generate_report(self, output_dir: str = "results") -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹ Ø§Ø² Ù†ØªØ§ÛŒØ¬ ØªØ³Øª"""
        if not self.test_results:
            logger.warning("No test results to report")
            return {}
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡
        summary = {
            'test_suite': 'P900 Network Performance Analysis',
            'timestamp': datetime.now().isoformat(),
            'total_tests': len(self.test_results),
            'scenarios': []
        }
        
        for result in self.test_results:
            scenario_summary = {
                'name': result.metadata.scenario,
                'test_id': result.metadata.test_id,
                'duration': result.metadata.total_duration,
                'baseline': {
                    'rtt_ms': result.baseline_metrics['rtt']['mean'] if result.baseline_metrics else None,
                    'loss_percent': result.baseline_metrics['loss_rate'] if result.baseline_metrics else None
                }
            }
            
            # Ø§Ú¯Ø± ØªØ³Øª ØªØ±Ø§ÙÛŒÚ© Ø¯Ø§Ø´Øª
            if result.under_traffic_metrics:
                scenario_summary['under_traffic'] = {
                    'rtt_ms': result.under_traffic_metrics['rtt']['mean'],
                    'loss_percent': result.under_traffic_metrics['loss_rate'],
                    'jitter_ms': result.under_traffic_metrics['jitter']['mean']
                }
                
            if result.traffic_metrics:
                scenario_summary['traffic'] = {
                    'target_bps': result.traffic_metrics['target_bandwidth'],
                    'actual_bps': result.traffic_metrics['actual_bandwidth'],
                    'total_packets': result.traffic_metrics['total_packets']
                }
                
            if result.correlation_analysis:
                scenario_summary['correlation'] = {
                    'coefficient': result.correlation_analysis['correlation_coefficient'],
                    'r_squared': result.correlation_analysis['r_squared']
                }
                
            summary['scenarios'].append(scenario_summary)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ JSON
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        json_path = output_path / f"p900_test_{timestamp}_results.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ
        text_report = self._generate_text_report(summary)
        text_path = output_path / f"p900_test_{timestamp}_summary.txt"
        with open(text_path, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        logger.info(f"\nğŸ“Š Reports saved to:")
        logger.info(f"   JSON: {json_path}")
        logger.info(f"   Text: {text_path}")
        
        return summary

    def _generate_text_report(self, summary: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù†"""
        lines = []
        lines.append("="*70)
        lines.append("P900 NETWORK PERFORMANCE TEST REPORT")
        lines.append("="*70)
        lines.append(f"Generated: {summary['timestamp']}")
        lines.append(f"Total Tests: {summary['total_tests']}")
        lines.append("")
        
        for scenario in summary['scenarios']:
            lines.append("-"*50)
            lines.append(f"SCENARIO: {scenario['name']}")
            lines.append(f"Test ID: {scenario['test_id']}")
            lines.append(f"Duration: {scenario['duration']:.1f} seconds")
            lines.append("")
            
            # Baseline results
            if scenario['baseline']:
                lines.append("Baseline Performance (No Traffic):")
                lines.append(f"  â€¢ RTT: {scenario['baseline']['rtt_ms']:.2f} ms")
                lines.append(f"  â€¢ Loss: {scenario['baseline']['loss_percent']:.1f}%")
                lines.append("")
            
            # Under traffic results
            if 'under_traffic' in scenario:
                lines.append("Performance Under Traffic:")
                lines.append(f"  â€¢ RTT: {scenario['under_traffic']['rtt_ms']:.2f} ms")
                lines.append(f"  â€¢ Loss: {scenario['under_traffic']['loss_percent']:.1f}%")
                lines.append(f"  â€¢ Jitter: {scenario['under_traffic']['jitter_ms']:.2f} ms")
                
                # Calculate impact
                if scenario['baseline']:
                    rtt_increase = scenario['under_traffic']['rtt_ms'] - scenario['baseline']['rtt_ms']
                    rtt_increase_pct = (rtt_increase / scenario['baseline']['rtt_ms'] * 100) if scenario['baseline']['rtt_ms'] > 0 else 0
                    lines.append(f"  â€¢ RTT Increase: +{rtt_increase:.2f} ms ({rtt_increase_pct:+.1f}%)")
                lines.append("")
            
            # Traffic statistics
            if 'traffic' in scenario:
                lines.append("Traffic Generation:")
                lines.append(f"  â€¢ Target Bandwidth: {scenario['traffic']['target_bps']:.0f} bps")
                lines.append(f"  â€¢ Actual Bandwidth: {scenario['traffic']['actual_bps']:.0f} bps")
                lines.append(f"  â€¢ Total Packets: {scenario['traffic']['total_packets']}")
                lines.append("")
            
            # Correlation analysis
            if 'correlation' in scenario:
                lines.append("Correlation Analysis:")
                lines.append(f"  â€¢ Correlation Coefficient: {scenario['correlation']['coefficient']:.3f}")
                lines.append(f"  â€¢ R-squared: {scenario['correlation']['r_squared']:.3f}")
                
                # Interpret correlation
                corr = abs(scenario['correlation']['coefficient'])
                if corr < 0.3:
                    interpretation = "Weak correlation - traffic has minimal impact on RTT"
                elif corr < 0.7:
                    interpretation = "Moderate correlation - traffic has noticeable impact on RTT"
                else:
                    interpretation = "Strong correlation - traffic significantly affects RTT"
                lines.append(f"  â€¢ Interpretation: {interpretation}")
                lines.append("")
        
        lines.append("="*70)
        lines.append("END OF REPORT")
        lines.append("="*70)
        
        return "\n".join(lines)

    def cleanup(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„Ø§Øª"""
        logger.info("\nğŸ§¹ Cleaning up resources...")
        
        # Stop any running threads
        self.traffic_active.set()
        
        # Wait for threads to complete
        if self.traffic_thread and self.traffic_thread.is_alive():
            self.traffic_thread.join(timeout=2)
            
        if self.probe_thread and self.probe_thread.is_alive():
            self.probe_thread.join(timeout=2)
        
        # Cleanup components
        self.integrator.cleanup()
        
        logger.info("âœ… Cleanup completed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main Entry Point
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_arguments():
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='P900 Network Performance Tester - Integrated MAVLink Traffic & RTT Analysis',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run baseline test only
  %(prog)s --master /dev/pts/6 --slave /dev/pts/8 --scenario baseline
  
  # Run all standard scenarios
  %(prog)s --master /dev/pts/6 --slave /dev/pts/8 --scenario all
  
  # Run specific traffic level
  %(prog)s --master /dev/pts/6 --slave /dev/pts/8 --scenario heavy
  
  # Custom output directory
  %(prog)s --master /dev/pts/6 --slave /dev/pts/8 --scenario all --output custom_results
        """
    )
    
    parser.add_argument(
        '--master', '-m',
        required=True,
        help='Master serial port path (e.g., /dev/pts/6)'
    )
    
    parser.add_argument(
        '--slave', '-s',
        required=True,
        help='Slave serial port path (e.g., /dev/pts/8)'
    )
    
    parser.add_argument(
        '--baudrate', '-b',
        type=int,
        default=57600,
        help='Serial baudrate (default: 57600)'
    )
    
    parser.add_argument(
        '--scenario',
        choices=['baseline', 'light', 'medium', 'heavy', 'all'],
        default='baseline',
        help='Test scenario to run (default: baseline)'
    )
    
    parser.add_argument(
        '--output', '-o',
        default='results',
        help='Output directory for results (default: results)'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Enable verbose logging'
    )
    
    return parser.parse_args()

def main():
    """Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
    args = parse_arguments()
    
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Header
    print("\n" + "="*70)
    print("ğŸš€ P900 NETWORK PERFORMANCE TESTER")
    print("   Integrated MAVLink Traffic & RTT Analysis")
    print("="*70)
    print(f"Master Port: {args.master}")
    print(f"Slave Port:  {args.slave}")
    print(f"Baudrate:    {args.baudrate}")
    print(f"Scenario:    {args.scenario}")
    print(f"Output Dir:  {args.output}")
    print("="*70 + "\n")
    
    # Create tester instance
    tester = IntegratedP900Tester(
        master_port=args.master,
        slave_port=args.slave,
        baudrate=args.baudrate
    )
    
    try:
        # Initialize system
        if not tester.initialize():
            logger.error("Failed to initialize system")
            return 1
        
        # Run scenarios
        if args.scenario == 'all':
            results = tester.run_all_scenarios()
        else:
            # Map string to enum
            scenario_map = {
                'baseline': TestScenario.BASELINE,
                'light': TestScenario.LIGHT_TRAFFIC,
                'medium': TestScenario.MEDIUM_TRAFFIC,
                'heavy': TestScenario.HEAVY_TRAFFIC
            }
            scenario = scenario_map[args.scenario]
            result = tester.run_scenario(scenario)
            results = [result] if result else []
        
        # Generate report
        if results:
            tester.generate_report(args.output)
            
            # Print summary
            print("\n" + "="*70)
            print("ğŸ“Š TEST SUMMARY")
            print("="*70)
            
            for result in results:
                print(f"\nğŸ“Œ {result.metadata.scenario}")
                if result.baseline_metrics:
                    print(f"   Baseline RTT: {result.baseline_metrics['rtt']['mean']:.2f} ms")
                if result.under_traffic_metrics:
                    print(f"   Traffic RTT:  {result.under_traffic_metrics['rtt']['mean']:.2f} ms")
                if result.correlation_analysis and 'relative_changes' in result.correlation_analysis:
                    changes = result.correlation_analysis['relative_changes']
                    print(f"   RTT Increase: {changes['rtt_increase_ms']:.2f} ms ({changes['rtt_increase_percent']:.1f}%)")
            
            print("\n" + "="*70)
            print("âœ… All tests completed successfully!")
            print("="*70)
        else:
            logger.warning("No test results generated")
            
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ Test interrupted by user")
        return 130
        
    except Exception as e:
        logger.error(f"âŒ Unexpected error: {e}", exc_info=True)
        return 1
        
    finally:
        # Cleanup
        tester.cleanup()
        logger.info("ğŸ‘‹ Goodbye!")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())

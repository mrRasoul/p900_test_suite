#!/usr/bin/env python3
"""
Integrated P900 Network Performance Tester
ØªØ³ØªØ± ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªØ£Ø«ÛŒØ± ØªØ±Ø§ÙÛŒÚ© MAVLink Ø¨Ø± RTT Ø´Ø¨Ú©Ù‡ P900

Ø§ÛŒÙ† ØªØ³ØªØ± ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø²:
- TrafficSimulator: Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ±Ø§ÙÛŒÚ© MAVLink ÙˆØ§Ù‚Ø¹ÛŒ
- ProbeInjector: Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ RTT
- ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† ØªØ±Ø§ÙÛŒÚ© Ùˆ ØªØ£Ø®ÛŒØ±
"""

import time
import json
import threading
import queue
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict, field
from datetime import datetime
from enum import Enum
import logging
import numpy as np
import serial
import sys

# Import existing components
from traffic_simulator import TrafficSimulator
from probe_injector import ProbeInjector
from mavlink_profile import MAVLinkProfile
from packet_generator import PacketGenerator

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Data Structures and Enums
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestScenario(Enum):
    """Ø§Ù†ÙˆØ§Ø¹ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ØªØ³Øª"""
    BASELINE = "baseline"           # ÙÙ‚Ø· probeØŒ Ø¨Ø¯ÙˆÙ† ØªØ±Ø§ÙÛŒÚ©
    LIGHT_TRAFFIC = "light"        # 10% bandwidth utilization
    MEDIUM_TRAFFIC = "medium"      # 50% bandwidth utilization  
    HEAVY_TRAFFIC = "heavy"        # 90% bandwidth utilization
    BURST_TRAFFIC = "burst"        # ØªØ±Ø§ÙÛŒÚ© Ù…ØªØºÛŒØ±
    CUSTOM = "custom"              # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÙØ§Ø±Ø´ÛŒ

@dataclass
class ScenarioConfig:
    """Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ÛŒÚ© Ø³Ù†Ø§Ø±ÛŒÙˆ ØªØ³Øª"""
    name: str
    description: str
    traffic_enabled: bool
    target_bandwidth_bps: float
    probe_interval_ms: float
    probe_count: int
    test_duration_seconds: float
    warmup_seconds: float = 2.0
    cooldown_seconds: float = 1.0
    
@dataclass
class TestMetadata:
    """Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ ÛŒÚ© ØªØ³Øª"""
    test_id: str
    timestamp: str
    scenario: str
    serial_ports: Dict[str, str]
    baudrate: int
    total_duration: float = 0.0
    
@dataclass 
class CombinedResults:
    """Ù†ØªØ§ÛŒØ¬ ØªØ±Ú©ÛŒØ¨ÛŒ ØªØ³Øª"""
    metadata: TestMetadata
    baseline_metrics: Optional[Dict] = None
    traffic_metrics: Optional[Dict] = None
    under_traffic_metrics: Optional[Dict] = None
    correlation_analysis: Optional[Dict] = None
    raw_measurements: List[Dict] = field(default_factory=list)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Scenario Manager - Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ØªØ³Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ScenarioManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ØªØ³Øª"""
    
    # ØªØ¹Ø±ÛŒÙ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    PREDEFINED_SCENARIOS = {
        TestScenario.BASELINE: ScenarioConfig(
            name="Baseline",
            description="RTT measurement without traffic",
            traffic_enabled=False,
            target_bandwidth_bps=0,
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        ),
        TestScenario.LIGHT_TRAFFIC: ScenarioConfig(
            name="Light Traffic",
            description="10% bandwidth utilization",
            traffic_enabled=True,
            target_bandwidth_bps=5760,  # 10% of 57600
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        ),
        TestScenario.MEDIUM_TRAFFIC: ScenarioConfig(
            name="Medium Traffic",
            description="50% bandwidth utilization",
            traffic_enabled=True,
            target_bandwidth_bps=28800,  # 50% of 57600
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        ),
        TestScenario.HEAVY_TRAFFIC: ScenarioConfig(
            name="Heavy Traffic",
            description="90% bandwidth utilization",
            traffic_enabled=True,
            target_bandwidth_bps=51840,  # 90% of 57600
            probe_interval_ms=100,
            probe_count=100,
            test_duration_seconds=30
        )
    }
    
    @classmethod
    def get_scenario(cls, scenario_type: TestScenario) -> ScenarioConfig:
        """Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆ"""
        return cls.PREDEFINED_SCENARIOS.get(
            scenario_type,
            cls.PREDEFINED_SCENARIOS[TestScenario.BASELINE]
        )
    
    @classmethod
    def create_custom_scenario(cls, **kwargs) -> ScenarioConfig:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø³ÙØ§Ø±Ø´ÛŒ"""
        defaults = asdict(cls.PREDEFINED_SCENARIOS[TestScenario.BASELINE])
        defaults.update(kwargs)
        defaults['name'] = kwargs.get('name', 'Custom')
        defaults['description'] = kwargs.get('description', 'Custom scenario')
        return ScenarioConfig(**defaults)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Component Integrator - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ComponentIntegrator:
    """ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"""
    
    def __init__(self, master_port: str, slave_port: str, baudrate: int = 57600):
        """
        Args:
            master_port: Ù¾ÙˆØ±Øª Ù…Ø­Ù„ÛŒ (Master)
            slave_port: Ù¾ÙˆØ±Øª Ø¯ÙˆØ± (Slave) 
            baudrate: Ø³Ø±Ø¹Øª Ø³Ø±ÛŒØ§Ù„
        """
        self.master_port = master_port
        self.slave_port = slave_port
        self.baudrate = baudrate
        
        # Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
        self.traffic_simulator: Optional[TrafficSimulator] = None
        self.probe_injector: Optional[ProbeInjector] = None
        self.mavlink_profile: Optional[MAVLinkProfile] = None
        
        # Serial connections
        self.master_port: Optional[serial.Serial] = None
        self.slave_port: Optional[serial.Serial] = None
        
        # Component status
        self.components_ready = False
        self.serial_lock = threading.Lock()  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
        
    def initialize_serial_ports(self) -> bool:
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ§Ù„"""
        try:
            # Master port
            self.master_port = serial.Serial(
                port=self.master_port,
                baudrate=self.baudrate,
                timeout=0.1,
                write_timeout=1.0
            )
            logger.info(f"âœ… Master serial port opened: {self.master_port}")
            
            # Slave port  
            self.slave_port = serial.Serial(
                port=self.slave_port,
                baudrate=self.baudrate,
                timeout=0.1,
                write_timeout=1.0
            )
            logger.info(f"âœ… Slave serial port opened: {self.slave_port}")
            
            # Clear buffers
            self.master_port.reset_input_buffer()
            self.master_port.reset_output_buffer()
            self.slave_port.reset_input_buffer()
            self.slave_port.reset_output_buffer()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize serial ports: {e}")
            return False
    
    def create_traffic_simulator(self, target_bandwidth: float) -> TrafficSimulator:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø² ØªØ±Ø§ÙÛŒÚ©"""
        if not self.master_port:
            raise RuntimeError("Serial ports not initialized")
            
        self.traffic_simulator = TrafficSimulator(
            serial_port=self.master_port,
            target_bandwidth=target_bandwidth,
            write_lock=self.serial_lock 
        )
        logger.info(f"âœ… Traffic simulator created (target: {target_bandwidth} bps)")
        return self.traffic_simulator
    
    def create_probe_injector(self) -> ProbeInjector:
        """Ø§ÛŒØ¬Ø§Ø¯ ØªØ²Ø±ÛŒÙ‚â€ŒÚ©Ù†Ù†Ø¯Ù‡ probe"""
        if not self.master_port or not self.slave_port:
            raise RuntimeError("Serial ports not initialized")
            
        self.probe_injector = ProbeInjector(
            master_port=self.master_port,
            slave_port=self.slave_port
        )
        logger.info("âœ… Probe injector created")
        return self.probe_injector
    
    def load_mavlink_profile(self, profile_path: Optional[str] = None) -> MAVLinkProfile:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ MAVLink"""
        self.mavlink_profile = MAVLinkProfile(profile_path)
        logger.info("âœ… MAVLink profile loaded")
        return self.mavlink_profile
    
    def cleanup(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
        if self.master_port and self.master_port.is_open:
            self.master_port.close()
            logger.info("Master serial port closed")
            
        if self.slave_port and self.slave_port.is_open:
            self.slave_port.close()
            logger.info("Slave serial port closed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test Orchestrator - Ù‡Ù…Ø§Ù‡Ù†Ú¯â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§ØµÙ„ÛŒ ØªØ³Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class IntegratedP900Tester:
    """ØªØ³ØªØ± ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ P900 - ØªØ±Ú©ÛŒØ¨ ØªØ±Ø§ÙÛŒÚ© Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ RTT"""
    
    def __init__(self, master_port: str, slave_port: str, baudrate: int = 57600):
        """
        Args:
            master_port: Ù¾ÙˆØ±Øª Master (Ù…Ø­Ù„ÛŒ)
            slave_port: Ù¾ÙˆØ±Øª Slave (Ø¯ÙˆØ±)
            baudrate: Ø³Ø±Ø¹Øª Ø³Ø±ÛŒØ§Ù„
        """
        # Configuration
        self.master_port = master_port
        self.slave_port = slave_port
        self.baudrate = baudrate
        
        # Components
        self.integrator = ComponentIntegrator(master_port, slave_port, baudrate)
        self.scenario_manager = ScenarioManager()
        
        # Results storage
        self.test_results: List[CombinedResults] = []
        self.current_test: Optional[CombinedResults] = None
        
        # Thread management
        self.traffic_thread: Optional[threading.Thread] = None
        self.probe_thread: Optional[threading.Thread] = None
        self.monitor_thread: Optional[threading.Thread] = None
        
        # Synchronization
        self.test_running = False
        self.traffic_active = threading.Event()
        self.results_queue = queue.Queue()
        
        # Statistics
        self.traffic_stats = {}
        self.probe_stats = {}
        
    def initialize(self) -> bool:
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø³ÛŒØ³ØªÙ…"""
        logger.info("="*60)
        logger.info("ğŸš€ Initializing Integrated P900 Tester")
        logger.info("="*60)
        
        # Initialize serial ports
        if not self.integrator.initialize_serial_ports():
            logger.error("Failed to initialize serial ports")
            return False
        
        # Load MAVLink profile
        self.integrator.load_mavlink_profile()
        
        logger.info("âœ… System initialized successfully")
        return True
    
    def run_scenario(self, scenario: TestScenario) -> CombinedResults:
        """Ø§Ø¬Ø±Ø§ÛŒ ÛŒÚ© Ø³Ù†Ø§Ø±ÛŒÙˆ ØªØ³Øª Ú©Ø§Ù…Ù„"""
        config = self.scenario_manager.get_scenario(scenario)
        logger.info(f"\nğŸ“‹ Running scenario: {config.name}")
        logger.info(f"   Description: {config.description}")
        
        # Create test metadata
        test_id = f"p900_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        metadata = TestMetadata(
            test_id=test_id,
            timestamp=datetime.now().isoformat(),
            scenario=config.name,
            serial_ports={
                'master': self.master_port,
                'slave': self.slave_port
            },
            baudrate=self.baudrate
        )
        
        # Initialize results container
        self.current_test = CombinedResults(metadata=metadata)
        
        # Execute test phases
        start_time = time.perf_counter()
        
        try:
            # Phase 1: Baseline measurement (always)
            logger.info("\nğŸ“Š Phase 1: Baseline Measurement")
            baseline_metrics = self._run_baseline_measurement(config)
            self.current_test.baseline_metrics = baseline_metrics
            
            # Phase 2: Traffic + Probe (if traffic enabled)
            if config.traffic_enabled:
                logger.info("\nğŸ“Š Phase 2: Combined Traffic + Probe Measurement")
                combined_metrics = self._run_combined_measurement(config)
                self.current_test.under_traffic_metrics = combined_metrics['probe_metrics']
                self.current_test.traffic_metrics = combined_metrics['traffic_metrics']
                
                # Phase 3: Correlation analysis
                logger.info("\nğŸ“Š Phase 3: Correlation Analysis")
                correlation = self._analyze_correlation()
                self.current_test.correlation_analysis = correlation
            
            # Update metadata
            self.current_test.metadata.total_duration = time.perf_counter() - start_time
            
            # Store results
            self.test_results.append(self.current_test)
            
            logger.info(f"\nâœ… Scenario '{config.name}' completed successfully!")
            return self.current_test
            
        except Exception as e:
            logger.error(f"âŒ Error during scenario execution: {e}")
            raise
    
# Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø¯ p900_new_tester.py - Ø¨Ø®Ø´ Ø¯ÙˆÙ…
# Ø§ÛŒÙ† Ú©Ø¯ Ø±Ø§ Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯

    def _run_baseline_measurement(self, config: ScenarioConfig) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ baseline (Ø¨Ø¯ÙˆÙ† ØªØ±Ø§ÙÛŒÚ©)"""
        logger.info("  â±ï¸ Starting baseline measurement...")
        
        try:
            # Create probe injector Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª baseline
            probe = self.integrator.create_probe_injector()
            
            # ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
            probe.interval_ms = config.probe_interval_ms
            probe.timeout_ms = 500  # 500ms timeout
            
            # Ø´Ø±ÙˆØ¹ probe injection
            probe.start()
            
            # Ø§Ø¬Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Øª Ù…Ø´Ø®Øµ
            test_duration = min(config.test_duration_seconds, 30)  # Ø­Ø¯Ø§Ú©Ø«Ø± 30 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ baseline
            logger.info(f"  Running baseline for {test_duration} seconds...")
            
            start_time = time.perf_counter()
            while time.perf_counter() - start_time < test_duration:
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ù‡Ø± 5 Ø«Ø§Ù†ÛŒÙ‡
                if int(time.perf_counter() - start_time) % 5 == 0:
                    stats = probe.get_statistics()
                    logger.info(f"    Progress: Sent={stats.total_sent}, "
                              f"Received={stats.total_received}, "
                              f"Loss={stats.loss_rate:.1f}%")
                time.sleep(1)
            
            # ØªÙˆÙ‚Ù Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬
            probe.stop()
            final_stats = probe.get_statistics()
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
            baseline_metrics = {
                'probe_count': final_stats.total_sent,
                'successful_probes': final_stats.total_received,
                'loss_rate': final_stats.loss_rate,
                'rtt': {
                    'mean': final_stats.avg_rtt_ms,
                    'min': final_stats.min_rtt_ms,
                    'max': final_stats.max_rtt_ms,
                    'std': final_stats.std_rtt_ms,
                    'p95': final_stats.percentile_95_ms,
                    'p99': final_stats.percentile_99_ms
                },
                'jitter': {
                    'mean': final_stats.avg_jitter_ms,
                    'max': final_stats.max_jitter_ms
                },
                'test_duration': test_duration
            }
            
            logger.info(f"  âœ… Baseline complete: RTT={final_stats.avg_rtt_ms:.2f}ms, "
                       f"Loss={final_stats.loss_rate:.1f}%")
            
            return baseline_metrics
            
        except Exception as e:
            logger.error(f"âŒ Error in baseline measurement: {e}")
            raise
    
    def _run_combined_measurement(self, config: ScenarioConfig) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ (ØªØ±Ø§ÙÛŒÚ© + Ù¾Ø±ÙˆØ¨)"""
        logger.info("  ğŸ”„ Starting combined measurement...")
        
        try:
            # Phase 2.1: Start traffic generation
            traffic_sim = self.integrator.create_traffic_simulator(
                target_bandwidth=config.target_bandwidth_bps
            )
            
            # Ø´Ø±ÙˆØ¹ ØªØ±Ø§ÙÛŒÚ© Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            self.traffic_active.clear()
            traffic_thread = threading.Thread(
                target=self._run_traffic_generator,
                args=(traffic_sim, config.test_duration_seconds),
                name="TrafficGenerator"
            )
            traffic_thread.start()
            
            # ØµØ¨Ø± Ø¨Ø±Ø§ÛŒ warmup ØªØ±Ø§ÙÛŒÚ©
            logger.info(f"  â³ Warming up traffic for {config.warmup_seconds}s...")
            time.sleep(config.warmup_seconds)
            
            # Phase 2.2: Start probe injection with traffic
            probe = self.integrator.create_probe_injector()
            probe.interval_ms = config.probe_interval_ms
            probe.timeout_ms = 500
            
            probe.start()
            
            # Monitor both traffic and probes
            monitor_start = time.perf_counter()
            probe_duration = config.test_duration_seconds - config.warmup_seconds
            
            logger.info(f"  ğŸ“Š Measuring RTT under traffic load for {probe_duration}s...")
            
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¢Ù…Ø§Ø± Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ
            periodic_stats = []
            
            while time.perf_counter() - monitor_start < probe_duration:
                # Ø«Ø¨Øª Ø¢Ù…Ø§Ø± Ù‡Ø± Ø«Ø§Ù†ÛŒÙ‡
                current_time = time.perf_counter() - monitor_start
                
                # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
                probe_stats = probe.get_statistics()
                traffic_stats = traffic_sim.get_stats()
                
                periodic_stats.append({
                    'timestamp': current_time,
                    'probe_stats': {
                        'sent': probe_stats.total_sent,
                        'received': probe_stats.total_received,
                        'rtt_ms': probe_stats.avg_rtt_ms,
                        'loss_rate': probe_stats.loss_rate
                    },
                    'traffic_stats': {
                        'packets_sent': traffic_stats.get('packets_sent', 0),
                        'bytes_sent': traffic_stats.get('bytes_sent', 0),
                        'actual_bandwidth': traffic_stats.get('actual_bandwidth', 0)
                    }
                })
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØª Ù‡Ø± 5 Ø«Ø§Ù†ÛŒÙ‡
                if int(current_time) % 5 == 0 and int(current_time) > 0:
                    logger.info(f"    Progress: Time={int(current_time)}s, "
                              f"RTT={probe_stats.avg_rtt_ms:.2f}ms, "
                              f"Traffic={traffic_stats.get('actual_bandwidth', 0):.0f}bps")
                
                time.sleep(1)
            
            # ØªÙˆÙ‚Ù Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§
            logger.info("  ğŸ›‘ Stopping components...")
            probe.stop()
            self.traffic_active.set()  # Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªÙˆÙ‚Ù Ø¨Ù‡ traffic
            traffic_thread.join(timeout=2)
            
            # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
            final_probe_stats = probe.get_statistics()
            final_traffic_stats = traffic_sim.get_stats()
            
            # Ø³Ø§Ø®ØªØ§Ø± Ù†ØªØ§ÛŒØ¬ ØªØ±Ú©ÛŒØ¨ÛŒ
            combined_metrics = {
                'probe_metrics': {
                    'probe_count': final_probe_stats.total_sent,
                    'successful_probes': final_probe_stats.total_received,
                    'loss_rate': final_probe_stats.loss_rate,
                    'rtt': {
                        'mean': final_probe_stats.avg_rtt_ms,
                        'min': final_probe_stats.min_rtt_ms,
                        'max': final_probe_stats.max_rtt_ms,
                        'std': final_probe_stats.std_rtt_ms,
                        'p95': final_probe_stats.percentile_95_ms,
                        'p99': final_probe_stats.percentile_99_ms
                    },
                    'jitter': {
                        'mean': final_probe_stats.avg_jitter_ms,
                        'max': final_probe_stats.max_jitter_ms
                    }
                },
                'traffic_metrics': {
                    'target_bandwidth': config.target_bandwidth_bps,
                    'actual_bandwidth': final_traffic_stats.get('actual_bandwidth', 0),
                    'total_packets': final_traffic_stats.get('packets_sent', 0),
                    'total_bytes': final_traffic_stats.get('bytes_sent', 0),
                    'duration': final_traffic_stats.get('elapsed_time', 0),
                    'errors': final_traffic_stats.get('errors', 0)
                },
                'periodic_measurements': periodic_stats
            }
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± raw measurements Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø¹Ø¯ÛŒ
            self.current_test.raw_measurements = periodic_stats
            
            logger.info(f"  âœ… Combined measurement complete: "
                       f"RTT={final_probe_stats.avg_rtt_ms:.2f}ms under "
                       f"{final_traffic_stats.get('actual_bandwidth', 0):.0f}bps load")
            
            return combined_metrics
            
        except Exception as e:
            logger.error(f"âŒ Error in combined measurement: {e}")
            raise
    
    def _run_traffic_generator(self, traffic_sim: TrafficSimulator, duration: float):
        """Ø§Ø¬Ø±Ø§ÛŒ traffic generator Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡"""
        try:
            logger.debug("Traffic generator thread started")
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ public Ùˆ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
            start_time = time.perf_counter()
            
            # Ø§Ú¯Ø± TrafficSimulator Ù…ØªØ¯ start Ø¯Ø§Ø±Ø¯
            if hasattr(traffic_sim, 'start'):
                # Ø§Ø¬Ø±Ø§ Ø¯Ø± Ø­Ø§Ù„Øª non-blocking
                traffic_sim.running = True
                
                while not self.traffic_active.is_set():
                    if time.perf_counter() - start_time > duration:
                        break
                        
                    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù‡Ø± 100ms
                    time.sleep(0.1)
                
                traffic_sim.running = False
            else:
                # fallback: Ø§Ø±Ø³Ø§Ù„ Ø¯Ø³ØªÛŒ Ù¾Ú©Øªâ€ŒÙ‡Ø§
                while not self.traffic_active.is_set():
                    if time.perf_counter() - start_time > duration:
                        break
                    
                    # ØªÙˆÙ„ÛŒØ¯ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù¾Ú©Øª
                    packet = traffic_sim.packet_generator.generate_mavlink_traffic(100)
                    traffic_sim.serial_port.write(packet)
                    traffic_sim.stats['packets_sent'] += 1
                    traffic_sim.stats['bytes_sent'] += len(packet)
                    
                    # Ø±Ø¹Ø§ÛŒØª bandwidth
                    time.sleep(1.0 / traffic_sim.packets_per_second)
                    
        except Exception as e:
            logger.error(f"Error in traffic generator: {e}")

        
    def _analyze_correlation(self) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† ØªØ±Ø§ÙÛŒÚ© Ùˆ RTT"""
        logger.info("  ğŸ“ˆ Analyzing correlation...")
        
        if not self.current_test or not self.current_test.raw_measurements:
            logger.warning("No data available for correlation analysis")
            return {}
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ
            timestamps = []
            rtt_values = []
            bandwidth_values = []
            loss_rates = []
            
            for measurement in self.current_test.raw_measurements:
                timestamps.append(measurement['timestamp'])
                rtt_values.append(measurement['probe_stats']['rtt_ms'])
                bandwidth_values.append(measurement['traffic_stats']['actual_bandwidth'])
                loss_rates.append(measurement['probe_stats']['loss_rate'])
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numpy arrays
            rtt_array = np.array(rtt_values)
            bandwidth_array = np.array(bandwidth_values)
            loss_array = np.array(loss_rates)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
            if len(rtt_array) > 1 and len(bandwidth_array) > 1:
                # Correlation between bandwidth and RTT
                rtt_bandwidth_corr = np.corrcoef(bandwidth_array, rtt_array)[0, 1]
                
                # Correlation between bandwidth and loss
                loss_bandwidth_corr = np.corrcoef(bandwidth_array, loss_array)[0, 1] if np.std(loss_array) > 0 else 0
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ degradation factor
                if self.current_test.baseline_metrics and self.current_test.under_traffic_metrics:
                    baseline_rtt = self.current_test.baseline_metrics['rtt']['mean']
                    traffic_rtt = self.current_test.under_traffic_metrics['rtt']['mean']
                    degradation_factor = traffic_rtt / baseline_rtt if baseline_rtt > 0 else 0
                else:
                    degradation_factor = 0
                
                # ÛŒØ§ÙØªÙ† Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø­Ø±Ø§Ù†ÛŒ (Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ Ú©Ù‡ RTT Ø¨Ù‡ Ø´Ø¯Øª Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯)
                # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ù¾Ù‡Ù†Ø§ÛŒ Ø¨Ø§Ù†Ø¯ÛŒ Ú©Ù‡ RTT Ø¨ÛŒØ´ Ø§Ø² 2x baseline Ø´ÙˆØ¯
                critical_threshold = None
                if degradation_factor > 2:
                    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ù†Ù‚Ø·Ù‡ Ú©Ù‡ RTT > 2x baseline
                    baseline_rtt = self.current_test.baseline_metrics['rtt']['mean']
                    for i, rtt in enumerate(rtt_values):
                        if rtt > 2 * baseline_rtt:
                            critical_threshold = bandwidth_values[i]
                            break
                
                correlation_analysis = {
                    'rtt_traffic_correlation': float(rtt_bandwidth_corr) if not np.isnan(rtt_bandwidth_corr) else 0,
                    'loss_traffic_correlation': float(loss_bandwidth_corr) if not np.isnan(loss_bandwidth_corr) else 0,
                    'degradation_factor': degradation_factor,
                    'critical_bandwidth_threshold': critical_threshold,
                    'analysis_summary': {
                        'correlation_strength': self._interpret_correlation(rtt_bandwidth_corr),
                        'impact_level': self._interpret_degradation(degradation_factor)
                    }
                }
                
            else:
                correlation_analysis = {
                    'error': 'Insufficient data for correlation analysis'
                }
            
            logger.info(f"  âœ… Correlation analysis complete")
            return correlation_analysis
            
        except Exception as e:
            logger.error(f"Error in correlation analysis: {e}")
            return {'error': str(e)}

    def _interpret_correlation(self, correlation: float) -> str:
        """ØªÙØ³ÛŒØ± Ù…Ù‚Ø¯Ø§Ø± Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ"""
        if np.isnan(correlation):
            return "No correlation"
        
        abs_corr = abs(correlation)
        if abs_corr < 0.3:
            return "Weak"
        elif abs_corr < 0.7:
            return "Moderate"
        else:
            return "Strong"
    
    def _interpret_degradation(self, factor: float) -> str:
        """ØªÙØ³ÛŒØ± Ù…ÛŒØ²Ø§Ù† Ø§ÙØª Ú©ÛŒÙÛŒØª"""
        if factor < 1.5:
            return "Minimal impact"
        elif factor < 2.0:
            return "Moderate impact"
        elif factor < 3.0:
            return "Significant impact"
        else:
            return "Severe impact"
    
# Ø§Ø¯Ø§Ù…Ù‡ ÙØ§ÛŒÙ„ p900_new_tester.py Ø§Ø² Ø®Ø· 370

    def save_results(self, output_dir: str = "results"):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ³Øªâ€ŒÙ‡Ø§"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        for test_result in self.test_results:
            # Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ test_id
            filename = f"{test_result.metadata.test_id}_results.json"
            filepath = output_path / filename
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ dictionary Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡
            result_dict = {
                'metadata': asdict(test_result.metadata),
                'baseline_metrics': test_result.baseline_metrics,
                'traffic_metrics': test_result.traffic_metrics,
                'under_traffic_metrics': test_result.under_traffic_metrics,
                'correlation_analysis': test_result.correlation_analysis,
                'raw_measurements': test_result.raw_measurements[:10] if test_result.raw_measurements else []  # ÙÙ‚Ø· 10 Ù†Ù…ÙˆÙ†Ù‡ Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù…
            }
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ JSON
            with open(filepath, 'w') as f:
                json.dump(result_dict, f, indent=2, default=str)
            
            logger.info(f"ğŸ“ Results saved to: {filepath}")
            
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø®Ù„Ø§ØµÙ‡ Ù…ØªÙ†ÛŒ
            summary_file = output_path / f"{test_result.metadata.test_id}_summary.txt"
            self._create_summary_report(test_result, summary_file)
    
    def _create_summary_report(self, result: CombinedResults, filepath: Path):
        """Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡ Ù…ØªÙ†ÛŒ"""
        with open(filepath, 'w') as f:
            f.write("="*70 + "\n")
            f.write(" P900 INTEGRATED TEST REPORT\n")
            f.write("="*70 + "\n\n")
            
            # Metadata
            f.write(f"Test ID: {result.metadata.test_id}\n")
            f.write(f"Scenario: {result.metadata.scenario}\n")
            f.write(f"Timestamp: {result.metadata.timestamp}\n")
            f.write(f"Duration: {result.metadata.total_duration:.2f} seconds\n")
            f.write(f"Serial Ports: {result.metadata.serial_ports['master']} <-> {result.metadata.serial_ports['slave']}\n")
            f.write(f"Baudrate: {result.metadata.baudrate}\n")
            f.write("\n")
            
            # Baseline Results
            if result.baseline_metrics:
                f.write("-"*70 + "\n")
                f.write("BASELINE MEASUREMENTS (No Traffic)\n")
                f.write("-"*70 + "\n")
                f.write(f"Probes Sent: {result.baseline_metrics['probe_count']}\n")
                f.write(f"Successful: {result.baseline_metrics['successful_probes']}\n")
                f.write(f"Loss Rate: {result.baseline_metrics['loss_rate']:.2f}%\n")
                f.write(f"RTT Mean: {result.baseline_metrics['rtt']['mean']:.3f} ms\n")
                f.write(f"RTT Min/Max: {result.baseline_metrics['rtt']['min']:.3f} / {result.baseline_metrics['rtt']['max']:.3f} ms\n")
                f.write(f"RTT Std Dev: {result.baseline_metrics['rtt']['std']:.3f} ms\n")
                f.write(f"RTT 95th %ile: {result.baseline_metrics['rtt']['p95']:.3f} ms\n")
                f.write(f"Jitter Mean: {result.baseline_metrics['jitter']['mean']:.3f} ms\n")
                f.write("\n")
            
            # Traffic Results
            if result.traffic_metrics:
                f.write("-"*70 + "\n")
                f.write("TRAFFIC GENERATION\n")
                f.write("-"*70 + "\n")
                f.write(f"Target Bandwidth: {result.traffic_metrics['target_bandwidth']:.0f} bps\n")
                f.write(f"Actual Bandwidth: {result.traffic_metrics['actual_bandwidth']:.0f} bps\n")
                f.write(f"Accuracy: {(result.traffic_metrics['actual_bandwidth']/result.traffic_metrics['target_bandwidth']*100):.1f}%\n")
                f.write(f"Total Packets: {result.traffic_metrics['total_packets']}\n")
                f.write(f"Total Bytes: {result.traffic_metrics['total_bytes']}\n")
                f.write(f"Errors: {result.traffic_metrics['errors']}\n")
                f.write("\n")
            
            # Under Traffic Results
            if result.under_traffic_metrics:
                f.write("-"*70 + "\n")
                f.write("RTT MEASUREMENTS UNDER TRAFFIC\n")
                f.write("-"*70 + "\n")
                f.write(f"Probes Sent: {result.under_traffic_metrics['probe_count']}\n")
                f.write(f"Successful: {result.under_traffic_metrics['successful_probes']}\n")
                f.write(f"Loss Rate: {result.under_traffic_metrics['loss_rate']:.2f}%\n")
                f.write(f"RTT Mean: {result.under_traffic_metrics['rtt']['mean']:.3f} ms\n")
                f.write(f"RTT Min/Max: {result.under_traffic_metrics['rtt']['min']:.3f} / {result.under_traffic_metrics['rtt']['max']:.3f} ms\n")
                f.write(f"RTT Std Dev: {result.under_traffic_metrics['rtt']['std']:.3f} ms\n")
                f.write(f"RTT 95th %ile: {result.under_traffic_metrics['rtt']['p95']:.3f} ms\n")
                f.write(f"Jitter Mean: {result.under_traffic_metrics['jitter']['mean']:.3f} ms\n")
                f.write("\n")
            
            # Correlation Analysis
            if result.correlation_analysis:
                f.write("-"*70 + "\n")
                f.write("CORRELATION ANALYSIS\n")
                f.write("-"*70 + "\n")
                
                if 'error' not in result.correlation_analysis:
                    f.write(f"RTT-Traffic Correlation: {result.correlation_analysis.get('rtt_traffic_correlation', 0):.3f}\n")
                    f.write(f"Loss-Traffic Correlation: {result.correlation_analysis.get('loss_traffic_correlation', 0):.3f}\n")
                    f.write(f"Performance Degradation Factor: {result.correlation_analysis.get('degradation_factor', 0):.2f}x\n")
                    
                    if result.correlation_analysis.get('critical_bandwidth_threshold'):
                        f.write(f"Critical Bandwidth Threshold: {result.correlation_analysis['critical_bandwidth_threshold']:.0f} bps\n")
                    
                    if 'analysis_summary' in result.correlation_analysis:
                        summary = result.correlation_analysis['analysis_summary']
                        f.write(f"Correlation Strength: {summary.get('correlation_strength', 'Unknown')}\n")
                        f.write(f"Impact Level: {summary.get('impact_level', 'Unknown')}\n")
                else:
                    f.write(f"Error: {result.correlation_analysis['error']}\n")
                f.write("\n")
            
            # Comparison Summary
            if result.baseline_metrics and result.under_traffic_metrics:
                f.write("="*70 + "\n")
                f.write("IMPACT SUMMARY\n")
                f.write("="*70 + "\n")
                
                baseline_rtt = result.baseline_metrics['rtt']['mean']
                traffic_rtt = result.under_traffic_metrics['rtt']['mean']
                rtt_increase = traffic_rtt - baseline_rtt
                rtt_increase_percent = (rtt_increase / baseline_rtt * 100) if baseline_rtt > 0 else 0
                
                baseline_loss = result.baseline_metrics['loss_rate']
                traffic_loss = result.under_traffic_metrics['loss_rate']
                loss_increase = traffic_loss - baseline_loss
                
                f.write(f"RTT Increase: {rtt_increase:.3f} ms ({rtt_increase_percent:+.1f}%)\n")
                f.write(f"Loss Rate Change: {loss_increase:+.2f}%\n")
                
                # ØªÙØ³ÛŒØ± Ù†ØªØ§ÛŒØ¬
                f.write("\nInterpretation:\n")
                if rtt_increase_percent < 20:
                    f.write("âœ… Minimal impact on latency - Network handling traffic well\n")
                elif rtt_increase_percent < 50:
                    f.write("âš ï¸ Moderate impact on latency - Some congestion occurring\n")
                elif rtt_increase_percent < 100:
                    f.write("âš ï¸ Significant impact on latency - Notable congestion\n")
                else:
                    f.write("âŒ Severe impact on latency - Heavy congestion detected\n")
                
                if loss_increase < 1:
                    f.write("âœ… No significant packet loss increase\n")
                elif loss_increase < 5:
                    f.write("âš ï¸ Minor packet loss increase\n")
                else:
                    f.write("âŒ Significant packet loss under load\n")
            
            f.write("\n" + "="*70 + "\n")
            f.write("END OF REPORT\n")
            f.write("="*70 + "\n")
        
        logger.info(f"ğŸ“„ Summary report saved to: {filepath}")
    
    def run_all_scenarios(self):
        """Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        scenarios = [
            TestScenario.BASELINE,
            TestScenario.LIGHT_TRAFFIC,
            TestScenario.MEDIUM_TRAFFIC,
            TestScenario.HEAVY_TRAFFIC
        ]
        
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ Running ALL Standard Scenarios")
        logger.info("="*60)
        
        for scenario in scenarios:
            try:
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“‹ Scenario: {scenario.value}")
                logger.info(f"{'='*60}")
                
                result = self.run_scenario(scenario)
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† delay Ø¨ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§
                if scenario != scenarios[-1]:
                    logger.info("\nâ³ Waiting 5 seconds before next scenario...")
                    time.sleep(5)
                    
            except Exception as e:
                logger.error(f"Failed to run scenario {scenario.value}: {e}")
                continue
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
        self.save_results()
        
        logger.info("\n" + "="*60)
        logger.info("âœ… All scenarios completed!")
        logger.info(f"ğŸ“Š Total tests run: {len(self.test_results)}")
        logger.info("="*60)
    
    def cleanup(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
        logger.info("Cleaning up resources...")
        
        # ØªÙˆÙ‚Ù thread Ù‡Ø§ Ø¯Ø± ØµÙˆØ±Øª ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù†
        self.traffic_active.set()
        
        # Ø¨Ø³ØªÙ† Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ§Ù„
        self.integrator.cleanup()
        
        logger.info("Cleanup completed")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main Entry Point
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='P900 Integrated Network Performance Tester'
    )
    parser.add_argument('--master', '-m', 
                       default='/dev/pts/6',
                       help='Master serial port')
    parser.add_argument('--slave', '-s',
                       default='/dev/pts/8', 
                       help='Slave serial port')
    parser.add_argument('--baudrate', '-b',
                       type=int, default=57600,
                       help='Serial baudrate')
    parser.add_argument('--scenario',
                       choices=['baseline', 'light', 'medium', 'heavy', 'all'],
                       default='all',
                       help='Test scenario to run')
    parser.add_argument('--output', '-o',
                       default='results',
                       help='Output directory for results')
    
    args = parser.parse_args()
    
    # Ø§ÛŒØ¬Ø§Ø¯ ØªØ³ØªØ±
    tester = IntegratedP900Tester(
        master_port=args.master,
        slave_port=args.slave,
        baudrate=args.baudrate
    )
    
    try:
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…
        if not tester.initialize():
            logger.error("Failed to initialize system")
            return 1
        
# Ø§Ø¯Ø§Ù…Ù‡ ÙØ§ÛŒÙ„ p900_new_tester.py Ø§Ø² Ø®Ø· 560
# Ø§ÛŒÙ† Ú©Ø¯ Ø±Ø§ Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯

        # Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆ(Ù‡Ø§)
        if args.scenario == 'all':
            tester.run_all_scenarios()
        else:
            # Ø§Ø¬Ø±Ø§ÛŒ ÛŒÚ© Ø³Ù†Ø§Ø±ÛŒÙˆ Ø®Ø§Øµ
            scenario_map = {
                'baseline': TestScenario.BASELINE,
                'light': TestScenario.LIGHT_TRAFFIC,
                'medium': TestScenario.MEDIUM_TRAFFIC,
                'heavy': TestScenario.HEAVY_TRAFFIC
            }
            
            scenario = scenario_map.get(args.scenario)
            if scenario:
                result = tester.run_scenario(scenario)
                tester.save_results(args.output)
            else:
                logger.error(f"Unknown scenario: {args.scenario}")
                return 1
        
        logger.info("\n" + "="*60)
        logger.info("âœ… Test execution completed successfully!")
        logger.info("="*60)
        
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ Test interrupted by user")
        
    except Exception as e:
        logger.error(f"âŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()
        return 1
        
    finally:
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        tester.cleanup()
        logger.info("ğŸ‘‹ Goodbye!")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
